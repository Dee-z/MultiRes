{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from random import shuffle\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import evaluate_plot as eval_plot\n",
    "import batchify as batchify\n",
    "import dbm as dbm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import os\n",
    "# 1 starts the process on GPU-0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../../Data/final_Physionet_avg_new.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is just for testing\n",
    "# data['train_ids'] = data['train_ids'][:5]\n",
    "# data['val_ids'] = data['val_ids'][:5]\n",
    "# data['test_ids'] = data['test_ids'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bilstm_flag':True,\n",
    "        'hidden_dim' : 700,\n",
    "        'dropout' : 0.9,\n",
    "        'layers' : 1,\n",
    "        'tagset_size' : 2,\n",
    "        'bilstm_flag' : True,\n",
    "        'attn_category' : 'dot',\n",
    "        'num_features' : 37,\n",
    "        'imputation_layer_dim_op':15,\n",
    "        'selected_feats' : 5,\n",
    "        'batch_size':1,\n",
    "        'same_device':True,\n",
    "        'same_feat_other_device':False,\n",
    "        'model_name':'VDBM-Phy-3rd-'}\n",
    "pickle.dump(params, open('../../Models/config_'+params['model_name']+'.pt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN = dbm.RNN_osaka(params).cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model_RNN.parameters(), lr=0.01, weight_decay=0.00005)\n",
    "optimizer = optim.SGD(model_RNN.parameters(), lr=0.0001, weight_decay=0.00000000002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'normal'\n",
    "if(mode=='normal'):\n",
    "    feature_ind = 0\n",
    "    label_ind = -1\n",
    "    print \"NORMAL mode with Flags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 45\n",
    "save_flag = True\n",
    "dict_df_prf_mod = {}\n",
    "print \"==x==\"*20\n",
    "print \"Data Statistics\"\n",
    "print \"Train Data: \"+str(len(data['train_ids']))\n",
    "print \"Val Data: \"+str(len(data['val_ids']))\n",
    "print \"Test Data: \"+str(len(data['test_ids']))\n",
    "print \"==x==\"*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "end_epoch = 60\n",
    "model_name = params['model_name']\n",
    "for iter_ in range(start_epoch, end_epoch):\n",
    "    print \"=#=\"*5+str(iter_)+\"=#=\"*5\n",
    "    total_loss = 0\n",
    "    preds_train = []\n",
    "    actual_train = []\n",
    "    for each_ID in tqdm(data['train_ids']):\n",
    "        model_RNN.zero_grad()\n",
    "        tag_scores = model_RNN(data['data'], each_ID)\n",
    "        \n",
    "        _, ind_ = torch.max(tag_scores, dim=1)\n",
    "        preds_train+=ind_.tolist()\n",
    "        # For this dataset the label is in -2\n",
    "        curr_labels = [data['data'][each_ID][label_ind]]\n",
    "        curr_labels = [batchify.label_mapping[x] for x in curr_labels]\n",
    "        actual_train+=curr_labels\n",
    "        curr_labels = torch.cuda.LongTensor(curr_labels)\n",
    "        curr_labels = autograd.Variable(curr_labels)\n",
    "        \n",
    "        loss = loss_function(tag_scores, curr_labels.reshape(tag_scores.shape[0]))\n",
    "        total_loss+=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    df_tr = pd.DataFrame(list(precision_recall_fscore_support(actual_train, preds_train, \n",
    "                                                              labels = [0,1])),\n",
    "                                                             columns = [0,1])\n",
    "    df_tr.index = ['Precision','Recall','F-score','Count']\n",
    "    prf_tr = precision_recall_fscore_support(actual_train, preds_train, average='weighted')\n",
    "#     prf_tr, df_tr = evaluate_(model_RNN, data, 'train_ids')\n",
    "    prf_test, df_test = eval_plot.evaluate_dbm(model_RNN, data, 'test_ids')\n",
    "    prf_val, df_val = eval_plot.evaluate_dbm(model_RNN, data, 'val_ids')\n",
    "    \n",
    "    df_all = pd.concat([df_tr, df_val, df_test],axis=1)\n",
    "    dict_df_prf_mod['Epoch'+str(iter_)] = df_all\n",
    "    \n",
    "    print '=='*5 + \"Epoch No:\"+str(iter_) +\"==\"*5\n",
    "    print \"Training Loss: \"+str(total_loss)\n",
    "    print \"==\"*4\n",
    "    print \"Train: \" + str(prf_tr)\n",
    "    print df_tr\n",
    "    print \"--\"*4\n",
    "    print \"Val: \" + str(prf_val)\n",
    "    print df_val\n",
    "    print \"--\"*4\n",
    "    print \"Test: \" + str(prf_test)\n",
    "    print df_test\n",
    "    print '=='*40\n",
    "    print '\\n'\n",
    "    if(save_flag):\n",
    "        torch.save(model_RNN, '../../Models/'+model_name+str(iter_)+'.pt')\n",
    "        pickle.dump(dict_df_prf_mod, open('../../Results/dict_prf_'+model_name+str(iter_)+'.pkl','wb'))\n",
    "        eval_plot.plot_graphs(dict_df_prf_mod, 'F-score', \n",
    "                              '../../Plots/'+model_name+str(iter_)+'.png',\n",
    "                              0, iter_+1, \n",
    "                              model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        eval_plot.plot_graphs(dict_df_prf_mod, 'F-score', \n",
    "                              '../../Plots/'+model_name+str(iter_)+'.png',\n",
    "                              0, iter_, \n",
    "                              model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
