{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(0, os.path.join(cwd, \"../\"))\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import src.bin.tensorify as tensorify\n",
    "import src.utils.data_conversion_utils as conversions\n",
    "import src.data_manager.student_life_var_binned_data_manager as data_manager\n",
    "import src.bin.trainer as trainer\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from torch import nn\n",
    "from src import definitions\n",
    "from src.bin import validations\n",
    "from src.bin import statistics\n",
    "from src.bin import plotting\n",
    "from src.utils.read_utils import read_pickle\n",
    "from src.utils import student_utils\n",
    "from src.data_manager import sub_sampler\n",
    "from src.data_manager import cross_val\n",
    "from src.data_manager import helper as data_manager_helper\n",
    "\n",
    "from tabulate import tabulate \n",
    "import src.models.simple as simple_models   \n",
    "\n",
    "pd.set_option('max_rows', 10000)\n",
    "\n",
    "importlib.reload(validations)\n",
    "importlib.reload(data_manager_helper)\n",
    "importlib.reload(sub_sampler)\n",
    "importlib.reload(statistics)\n",
    "importlib.reload(cross_val)\n",
    "importlib.reload(definitions)\n",
    "importlib.reload(conversions)\n",
    "importlib.reload(tensorify)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(trainer)\n",
    "importlib.reload(data_manager)\n",
    "importlib.reload(student_utils)\n",
    "importlib.reload(simple_models)\n",
    "feature_list = data_manager.FEATURE_LIST\n",
    "\n",
    "##### Pickle ######\n",
    "data = read_pickle('../data/training_data/most_representative_6_hr_b_imputed_normalized_prev_stress_data.pkl')\n",
    "\n",
    "### Data ####\n",
    "\n",
    "student_list = [53, 46, 7, 49, 22, 24, 2]\n",
    "data = data_manager.get_data_for_training_in_dict_format(*student_list, normalize=True, \n",
    "                                                         fill_na=True, flatten_sequence=False)\n",
    "\n",
    "# data = sub_sampler.get_sub_sampled_sequences(data)\n",
    "\n",
    "# print(data['data'].keys())\n",
    "# print(data['data']['2_4_16_4_1'][-1])\n",
    "\n",
    "\n",
    "#### Randomize ######\n",
    "train_ids, val_ids, test_ids = cross_val.random_stratified_splits(data)\n",
    "data['train_ids'] = train_ids\n",
    "data['val_ids'] = val_ids\n",
    "data['test_ids'] = test_ids\n",
    "\n",
    "############# Stats ########### \n",
    "# unnormalized_data = data_manager.get_data_for_training_in_dict_format(*student_list, normalize=False, fill_na=False)\n",
    "# statistics_df, raw_df = statistics.get_statistics_on_data_dict(unnormalized_data, feature_list)\n",
    "print(statistics.get_train_test_val_label_counts_from_raw_data(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Init ##################################\n",
    "hidden_size = 64\n",
    "dropout = 0.85\n",
    "learning_rate = 0.00005\n",
    "n_epochs = 150\n",
    "first_key = next(iter(data['data'].keys()))\n",
    "num_features = len(data['data'][first_key][0][0])\n",
    "covariates = len(data['data'][first_key][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tensorify.tensorify_data_gru_d(data)\n",
    "\n",
    "\n",
    "val_f1_over_splits = []\n",
    "test_f1_over_splits = []\n",
    "\n",
    "for data, left_out_student in [(data, 1)]:\n",
    "    \n",
    "    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    print(\"Left Out Student: \", left_out_student)\n",
    "    \n",
    "    model = simple_models.SimpleLSTM(num_features=num_features,\n",
    "                                     num_classes=3,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     bidirectional=True,\n",
    "                                     dropout=dropout,\n",
    "                                     covariates=covariates)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "\n",
    "    best_val_f1 = 0\n",
    "    best_test_f1 = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_labels, train_preds =  trainer.evaluate_set(data, 'train_ids', model, criterion, optimizer, \n",
    "                                                                      train_covariates=True)\n",
    "        val_loss, val_labels, val_preds =  trainer.evaluate_set(data, 'val_ids', model, criterion, \n",
    "                                                                train_covariates=True)\n",
    "        test_loss, test_labels, test_preds =  trainer.evaluate_set(data, 'test_ids', model, criterion, \n",
    "                                                                   train_covariates=True)\n",
    "\n",
    "        loss_over_epochs['train_loss'].append(train_loss)\n",
    "        loss_over_epochs['val_loss'].append(val_loss)\n",
    "        loss_over_epochs['test_loss'].append(test_loss)\n",
    "\n",
    "        train_scores = metrics.precision_recall_fscore_support(train_labels, train_preds, average='weighted')\n",
    "        val_scores = metrics.precision_recall_fscore_support(val_labels, val_preds, average='weighted')\n",
    "        test_scores = metrics.precision_recall_fscore_support(test_labels, test_preds, average='weighted')\n",
    "\n",
    "        scores_over_epochs['train_scores'].append(train_scores)\n",
    "        scores_over_epochs['val_scores'].append(val_scores)\n",
    "        scores_over_epochs['test_scores'].append(test_scores)\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print(\"xxxxxxxxxxxxxx epoch: {} xxxxxxxxxxxxxx\".format(epoch))\n",
    "            plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='f1', fig_size=(8,5))\n",
    "            plotting.plot_loss_over_n_epochs(loss_over_epochs, fig_size=(8, 5))\n",
    "            print(\"Cofusion Matrix For Val Set: \")\n",
    "            print(tabulate( metrics.confusion_matrix(val_labels, val_preds)))\n",
    "            print(\"Predicted Label Distribution:\")\n",
    "            print(statistics.get_train_test_val_label_counts_from_predictions(train_preds, val_preds, test_preds))\n",
    "\n",
    "        best_test_f1 = test_scores[2] if best_test_f1 < test_scores[2] else best_test_f1\n",
    "        best_val_f1 = val_scores[2] if best_val_f1 < val_scores[2] else best_val_f1\n",
    "\n",
    "    val_f1_over_splits.append([left_out_student, best_val_f1])\n",
    "    test_f1_over_splits.append([left_out_student, best_test_f1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_f1_over_splits)\n",
    "print(test_f1_over_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['train_ids'])\n",
    "train_ids = set(data['train_ids'])\n",
    "\n",
    "# print(data['val_ids'])\n",
    "val_ids = set(data['val_ids'])\n",
    "\n",
    "# print(data['test_ids'])\n",
    "test_ids = set(data['test_ids'])\n",
    "\n",
    "print(train_ids.intersection(val_ids))\n",
    "print(val_ids.intersection(test_ids))\n",
    "print(train_ids.intersection(test_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
