{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student ID couldn't be converted to Integer!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(0, os.path.join(cwd, \"../\"))\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import src.bin.tensorify as tensorify\n",
    "import src.utils.data_conversion_utils as conversion_utils\n",
    "import src.data_manager.student_life_var_binned_data_manager as data_manager\n",
    "import src.bin.trainer as trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from torch import nn\n",
    "from src import definitions\n",
    "from src.bin import validations\n",
    "from src.bin import statistics\n",
    "from src.bin import plotting\n",
    "from src.utils.read_utils import read_pickle\n",
    "from src.utils import student_utils\n",
    "from src.data_manager import sub_sampler\n",
    "from src.data_manager import cross_val\n",
    "from src.data_manager import helper as data_manager_helper\n",
    "\n",
    "from tabulate import tabulate \n",
    "import src.models.simple as simple_models\n",
    "import src.models.gatis_mp as models\n",
    "\n",
    "pd.set_option('max_rows', 10000)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "feature_list = data_manager.FEATURE_LIST\n",
    "\n",
    "##### Pickle ######\n",
    "# data = read_pickle('../data/training_data/most_representative_6_hr_b_imputed_normalized_prev_stress_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function src.utils.data_conversion_utils.normalize(data_frame:pandas.core.frame.DataFrame, norm_type='mean', df_mean:pandas.core.series.Series=None, df_std:pandas.core.series.Series=None, df_min:pandas.core.series.Series=None, df_max:pandas.core.series.Series=None) -> pandas.core.frame.DataFrame>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.utils.data as torch_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "conversion_utils.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "      <th>displacement</th>\n",
       "      <th>distance_std</th>\n",
       "      <th>unique_tile_count</th>\n",
       "      <th>convex_hull_area</th>\n",
       "      <th>tile_change</th>\n",
       "      <th>cluster</th>\n",
       "      <th>entropy</th>\n",
       "      <th>start_term</th>\n",
       "      <th>end_term</th>\n",
       "      <th>mid_term</th>\n",
       "      <th>weekends</th>\n",
       "      <th>stress</th>\n",
       "      <th>student_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2013-04-20 05:14:22</td>\n",
       "      <td>4.809793</td>\n",
       "      <td>0.593052</td>\n",
       "      <td>0.148694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>919.462248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.829342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-04-21 17:20:08</td>\n",
       "      <td>0.775786</td>\n",
       "      <td>0.456714</td>\n",
       "      <td>0.053514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.719984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.257372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-03 08:22:11</td>\n",
       "      <td>44.803196</td>\n",
       "      <td>7.988767</td>\n",
       "      <td>1.985968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144195.933899</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.337196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time   distance  displacement  distance_std  \\\n",
       "73 2013-04-20 05:14:22   4.809793      0.593052      0.148694   \n",
       "24 2013-04-21 17:20:08   0.775786      0.456714      0.053514   \n",
       "7  2013-04-03 08:22:11  44.803196      7.988767      1.985968   \n",
       "\n",
       "    unique_tile_count  convex_hull_area  tile_change  cluster   entropy  \\\n",
       "73                1.0        919.462248          0.0      6.0  2.829342   \n",
       "24                1.0         25.719984          0.0      2.0  2.257372   \n",
       "7                 1.0     144195.933899         31.0      6.0  2.337196   \n",
       "\n",
       "    start_term  end_term  mid_term  weekends  stress  student_id  \n",
       "73         0.0       0.0       1.0       1.0     1.0          10  \n",
       "24         0.0       0.0       1.0       1.0     2.0           3  \n",
       "7          1.0       0.0       0.0       0.0     0.0          45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = module_path + \"/data\"\n",
    "gfp = lambda x: data_path + x\n",
    "# 1,3,5,9,13, 49\n",
    "file_path = gfp('/gatis-new-49.pkl')\n",
    "# file_path = gfp('/gatis-old-49.pkl')\n",
    "# file_path = data_path + \"/gatis_all.pkl\"\n",
    "# file_path = data_path + \"/gatis-old-all.pkl\"\n",
    "data = pd.read_pickle(file_path)\n",
    "display(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.98\n",
    "n_epochs = 300\n",
    "batch_size=32\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsimsiri/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{33.0, 2.0, 1.0, 4.0, 7.0, 10.0, 42.0, 46.0, 49.0, 22.0, 24.0}\n",
      "Fold: 0 train: 750 test: 56\n",
      "{33.0, 2.0, 1.0, 4.0, 7.0, 42.0, 10.0, 46.0, 49.0, 22.0, 24.0}\n",
      "Fold: 1 train: 750 test: 57\n",
      "{33.0, 2.0, 1.0, 4.0, 7.0, 42.0, 10.0, 46.0, 49.0, 22.0, 24.0}\n",
      "Fold: 2 train: 750 test: 67\n",
      "{33.0, 1.0, 2.0, 4.0, 7.0, 10.0, 42.0, 46.0, 49.0, 22.0, 24.0}\n",
      "Fold: 3 train: 750 test: 65\n",
      "{1.0, 2.0, 33.0, 4.0, 7.0, 42.0, 10.0, 46.0, 49.0, 22.0, 24.0}\n",
      "Fold: 4 train: 750 test: 66\n"
     ]
    }
   ],
   "source": [
    "# train_loader = DataLoader([X_train.values, y_train.values] ,batch_size=32, shuffle=True)\n",
    "# print(train_loader)\n",
    "def pd_to_loader(X, Y, batch_size=32, shuffle=False):\n",
    "    xt_train,yt_train = torch.Tensor(X), torch.LongTensor(Y)\n",
    "    yt_train = yt_train.view(-1, )\n",
    "    tensor_dataset_train = torch_utils.TensorDataset(xt_train, yt_train)\n",
    "    loader = DataLoader(tensor_dataset_train, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "    \n",
    "\n",
    "features_cols = ['distance', 'displacement', 'distance_std', 'unique_tile_count', 'convex_hull_area', 'tile_change', \n",
    "                 'cluster', 'entropy', 'start_term', 'end_term', 'mid_term', 'weekends']\n",
    "STUDENTS_LIST = set([1, 2,4, 7,10, 22, 24, 33, 42, 46, 49, 53, 57])\n",
    "\n",
    "all_cols = list(data)\n",
    "all_cols.remove('stress')\n",
    "all_cols.remove('student_id')\n",
    "all_cols.remove('time')\n",
    "features = data[all_cols + ['student_id','stress']]\n",
    "# display(features[:3])\n",
    "\n",
    "split_X = features.values.tolist()\n",
    "split_y = features['student_id'].tolist()\n",
    "split_y2 = features['stress'].tolist()\n",
    "split_student_labels = ['{}_{}'.format(split_y[i], int(split_y2[i])) for i in range(len(split_y))]\n",
    "kfolds = StratifiedKFold(n_splits=5)\n",
    "loaders = []\n",
    "\n",
    "print(int(features.iloc[0]['student_id']) in STUDENTS_LIST)\n",
    "for fold, (train_idx, test_idx) in enumerate(kfolds.split(split_X, split_student_labels)):\n",
    "\n",
    "    train_idx = np.random.choice(train_idx, min(len(train_idx), 750), replace=False).tolist()\n",
    "    test_idx  = np.random.choice(test_idx, min(len(test_idx), 180), replace=False).tolist()\n",
    "    \n",
    "    Xy_train = pd.DataFrame([features.iloc[i] for i in train_idx])\n",
    "#     Xy_test  = pd.DataFrame([features.iloc[i] for i in test_idx])\n",
    "\n",
    "    _test = [features.iloc[i] \n",
    "        if (int(features.iloc[i]['student_id']) in STUDENTS_LIST) else\n",
    "             None\n",
    "             for i in test_idx]\n",
    "    Xy_test  = pd.DataFrame(list(filter(lambda x: x is not None, _test)))\n",
    "    print(set(Xy_test['student_id'].values))\n",
    "\n",
    "    X_train, y_train = Xy_train[features_cols], Xy_train['stress']\n",
    "    X_test, y_test   = Xy_test[features_cols], Xy_test['stress']\n",
    "    X_train, y_train = conversion_utils.normalize(X_train), pd.DataFrame(y_train).values\n",
    "    X_test, y_test = conversion_utils.normalize(X_test), pd.DataFrame(y_test).values\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test  = X_test.values\n",
    "    print(\"Fold: {} train: {} test: {}\".format(fold, len(Xy_train), len(Xy_test)))\n",
    "    train_loader = pd_to_loader(X_train, y_train,batch_size=batch_size, shuffle=True)\n",
    "    test_loader = pd_to_loader(X_test, y_test, batch_size=batch_size)\n",
    "    loaders.append((train_loader, test_loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_network(loader, net, criterion, optimizer, training=False):\n",
    "    running_loss = 0.0\n",
    "    final_preds, final_labels = [], []\n",
    "    if training:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "    for i, minibatch in enumerate(loader, 0):\n",
    "        batch, labels = minibatch\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        final_preds += preds.numpy().tolist()\n",
    "        final_labels += labels.numpy().tolist()\n",
    "        loss = criterion(logits, labels)\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss, final_labels, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GatisNet(\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=57, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.35)\n",
      "    (3): Linear(in_features=57, out_features=35, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.25)\n",
      "    (6): Linear(in_features=35, out_features=35, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.15)\n",
      "    (9): Linear(in_features=35, out_features=3, bias=True)\n",
      "    (10): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = models.GatisNet()\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsimsiri/anaconda2/envs/python3/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/Users/nsimsiri/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT---\n",
      "(0.5419354838709677, 0.5, 0.47667638483965014)\n",
      "SPLIT---\n",
      "(0.4453661327231121, 0.42105263157894735, 0.3614306421323965)\n",
      "SPLIT---\n",
      "(0.36363636363636365, 0.4925373134328358, 0.4091308165057068)\n",
      "SPLIT---\n",
      "(0.5567166979362101, 0.46153846153846156, 0.4108528477759247)\n",
      "SPLIT---\n",
      "(0.4156260406260406, 0.3939393939393939, 0.38494751435927904)\n",
      "X==XX==XX==XX==XX==X\n",
      "(0.5419354838709677, 0.5, 0.47667638483965014)\n",
      "(0.4453661327231121, 0.42105263157894735, 0.3614306421323965)\n",
      "(0.36363636363636365, 0.4925373134328358, 0.4091308165057068)\n",
      "(0.5567166979362101, 0.46153846153846156, 0.4108528477759247)\n",
      "(0.4156260406260406, 0.3939393939393939, 0.38494751435927904)\n",
      "[(0.5419354838709677, 0.5, 0.47667638483965014), (0.4453661327231121, 0.42105263157894735, 0.3614306421323965), (0.36363636363636365, 0.4925373134328358, 0.4091308165057068), (0.5567166979362101, 0.46153846153846156, 0.4108528477759247), (0.4156260406260406, 0.3939393939393939, 0.38494751435927904)]\n",
      "best_test_f1: [0.465 0.454 0.409]\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "best_test_f1 = 0\n",
    "best_val_f1 = 0\n",
    "\n",
    "fold_train_scores = []\n",
    "fold_test_scores  = []\n",
    "fold_train_loss   = []\n",
    "fold_test_loss    = []\n",
    "\n",
    "for fold, (train_loader, test_loader) in enumerate(loaders):\n",
    "        net = models.GatisNet()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "        loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "        best_split_score = [0.0,0.0,0.0]\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            train_loss, train_labels, train_preds = eval_network(train_loader, net, criterion, optimizer, training=True)\n",
    "            test_loss, test_labels, test_preds = eval_network(test_loader, net, criterion, optimizer)\n",
    "            \n",
    "            train_scores = metrics.precision_recall_fscore_support(train_labels, train_preds, average='weighted')\n",
    "            test_scores = metrics.precision_recall_fscore_support(test_labels, test_preds, average='weighted')\n",
    "\n",
    "            scores_over_epochs['train_scores'].append(train_scores)\n",
    "            scores_over_epochs['val_scores'].append(test_scores)\n",
    "            scores_over_epochs['test_scores'].append(test_scores)\n",
    "\n",
    "            loss_over_epochs['train_loss'].append(train_loss)\n",
    "            loss_over_epochs['val_loss'].append(test_loss)\n",
    "            loss_over_epochs['test_loss'].append(test_loss)\n",
    "            if (best_split_score[2] < test_scores[2]):\n",
    "                best_split_score = test_scores[:-1]\n",
    "\n",
    "#             if epoch%5 == 0:\n",
    "#                 print(\"xxxxxxxxxxxxxx epoch: {} xxxxxxxxxxxxxx\".format(epoch))\n",
    "#                 plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='f1', fig_size=(8,5))\n",
    "#                 plotting.plot_loss_over_n_epochs(loss_over_epochs, fig_size=(8, 5))\n",
    "#                 print(\"Cofusion Matrix For Test Set: \")\n",
    "#                 print(tabulate( metrics.confusion_matrix(test_labels, test_preds)))\n",
    "        #         print(\"Predicted Label Distribution:\")\n",
    "        #         print(statistics.get_train_test_val_label_counts_from_predictions(train_preds, val_preds, test_preds))\n",
    "        fold_test_scores.append(best_split_score)\n",
    "        print(\"SPLIT---\")\n",
    "        print(best_split_score,)\n",
    "\n",
    "avg_test_scores  = np.mean(np.array(fold_test_scores), axis=0)\n",
    "\n",
    "print(\"X==X\"*5)\n",
    "for xx in fold_test_scores:\n",
    "    print(xx)\n",
    "print(fold_test_scores)\n",
    "print(\"best_test_f1: {}\".format(avg_test_scores))\n",
    "# print(\"best_val_f1: {}\".format(best_val_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_test_f1: 0.4086076411225915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.341"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"best_test_f1: {}\".format(avg_test_scores[2]))\n",
    "0.346\n",
    "0.341\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2222.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([2222,1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fod_cross_val_splits_stratified_by_students(data: dict, n_splits=5, stratification_type=\"student_label\"):\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    data_keys = data['data'].keys()\n",
    "    keys, labels = conversions.extract_keys_and_labels_from_dict(data)\n",
    "    student_ids = conversions.extract_student_ids_from_keys(keys)\n",
    "    student_ids_label = []\n",
    "\n",
    "    for i in range(len(student_ids)):\n",
    "        student_ids_label.append(str(student_ids[i]) + \"_\" + str(labels[i]))\n",
    "\n",
    "    student_ids_label = np.array(student_ids_label)\n",
    "    data_keys = np.array(list(data_keys))\n",
    "    student_ids = conversions.convert_list_of_strings_to_list_of_ints(student_ids)\n",
    "\n",
    "    if stratification_type == \"student\":\n",
    "        stratification_column = student_ids\n",
    "    else:\n",
    "        stratification_column = student_ids_label\n",
    "\n",
    "    print(stratification_type)\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=n_splits, random_state=SPLITTER_RANDOM_STATE)\n",
    "    for train_index, val_index in splitter.split(X=data_keys, y=stratification_column):\n",
    "\n",
    "        splitting_dict = {}\n",
    "        splitting_dict['train_ids'] = data_keys[train_index].tolist()\n",
    "        splitting_dict['val_ids'] = data_keys[val_index].tolist()\n",
    "        splits.append(splitting_dict)\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "current_data_agg = [0.582, 0.513, 0.424, 0.4003, 0.398, 0.382, 0.426]\n",
    "past_data_agg = [0.551, 0.456, 0.395, 0.392, 0.375, 0.373, 0.402] \n",
    "\n",
    "\n",
    "plt.plot(current_data_agg)\n",
    "plt.plot(past_data_agg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.657, 0.61 , 0.471, 0.446, 0.436])\n",
    "b = np.array([0.657, 0.634, 0.585, 0.60 , 0.583])\n",
    "print(np.abs(np.array(a-b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
