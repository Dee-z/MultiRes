{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: multitask_bilstm_attention\n"
     ]
    }
   ],
   "source": [
    "# import inspect\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# sys.path.insert(0, os.path.join(cwd, \"../\"))\n",
    "\n",
    "# from src import definitions\n",
    "# from src.experiments.multitask_learning.experiment_imports import *\n",
    "\n",
    "# # Derive Model name from the experiment script calling this module.\n",
    "# stack_trace = inspect.stack()\n",
    "# frame_info = stack_trace[-1]\n",
    "\n",
    "# if definitions.CLUSTER_MODE:\n",
    "#     frame_info = stack_trace[-3]\n",
    "\n",
    "# file_name = frame_info[1]\n",
    "# model_name = \"multitask_bilstm_attention\"\n",
    "# print(\"Model Name:\", model_name)\n",
    "\n",
    "# cuda_enabled = False\n",
    "\n",
    "# ##### Read Data and Statistics #####\n",
    "# data_file_path = os.path.join(definitions.SHUFFLED_DATA_ROOT,\n",
    "#                               'training_data_normalized_no_prev_stress_students_greater_than_40_labels.pkl')\n",
    "# data = read_pickle(data_file_path)\n",
    "# tensorified_data = tensorify.tensorify_data_gru_d(deepcopy(data), cuda_enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model Configs #####\n",
    "(use_histogram,\n",
    " autoencoder_bottle_neck_feature_size,\n",
    " autoencoder_num_layers,\n",
    " shared_hidden_layer_size,\n",
    " user_dense_layer_hidden_size,\n",
    " num_classes,\n",
    " decay,\n",
    " shared_layer_dropout_prob,\n",
    " user_head_dropout_prob,\n",
    " alpha,\n",
    " beta,\n",
    " learning_rate,\n",
    " n_epochs,\n",
    " bidirectional) = model_config_loader.load_static_configs_for_lstm_n_multitask_models(model_name)\n",
    "\n",
    "(num_features,\n",
    " num_covariates,\n",
    " device,\n",
    " class_weights,\n",
    " cuda_enabled,\n",
    " student_list) = model_config_loader.load_derived_configs_for_lstm_n_multitask_models(use_histogram, data)\n",
    "\n",
    "# K fold Cross val score.\n",
    "split_val_scores = []\n",
    "best_score_epoch_log = []\n",
    "best_models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_output_size 256, context_vector_size 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "from src.models.multitask_learning import multitask_biLSTM_attention\n",
    "\n",
    "importlib.reload(attention_module)\n",
    "importlib.reload(align)\n",
    "is_cuda = False\n",
    "dropout_p = 0.0\n",
    "\n",
    "MultiTaskBiLSTMAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([1, 25, 9])\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "single_input= tensorified_data['data']['4_3_28_2']\n",
    "actual_data_idx = definitions.ACTUAL_DATA_IDX\n",
    "\n",
    "covariate_data, histogram_data, labels = single_input[1], single_input[2], single_input[3]\n",
    "histogram_data = histogram_data.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-590f6799cafc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m####### Forward Pass #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder_outputs {} , context_vector {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_seq' is not defined"
     ]
    }
   ],
   "source": [
    "####### Forward Pass #######\n",
    "\n",
    "\n",
    "print(\"encoder_outputs {} , context_vector {}\".format(encoder_output_size, context_vector_size))\n",
    "\n",
    "weight_vector = attention(encoder_outputs, context_vector)\n",
    "print(\"weight_vector\", weight_vector.shape)\n",
    "\n",
    "expected_encoder_output = expected_context_vector_from_attention(encoder_outputs, context_vector)\n",
    "print(\"expected_encoder_output\", expected_encoder_output.shape)\n",
    "\n",
    "input_vector = input_seq[:, -1, :].unsqueeze(1)\n",
    "print(\"input_vector\", input_vector.shape)\n",
    "\n",
    "decoder_output, _ = decoder(input_vector=input_vector,\n",
    "        encoder_outputs=encoder_outputs,\n",
    "        previous_decoder_hidden_state=context_vector)\n",
    "\n",
    "# print(\"decoder_output\", decoder_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([4]) torch.Size([25, 9]) torch.Size([1])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(histogram_data))\n",
    "print(type(histogram_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
