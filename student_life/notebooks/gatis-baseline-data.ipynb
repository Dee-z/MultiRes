{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student ID couldn't be converted to Integer!\n",
      "Student ID couldn't be converted to Integer!\n",
      "/Users/nsimsiri/Documents/code/ml/MultiRes/student_life\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "cwd = os.getcwd()\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "sys.path.insert(0, os.path.join(cwd, \"../\"))\n",
    "sys.path.insert(0, os.path.join(cwd, \"../student_life/\"))\n",
    "sys.path.insert(0, os.path.join(cwd, \"../student_life/src/\"))\n",
    "sys.path.insert(0, os.path.join(cwd, \"../student_life/src/bin/\"))\n",
    "\n",
    "\n",
    "import copy\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import importlib\n",
    "import src.utils.student_utils as student_utils\n",
    "import src.utils.data_conversion_utils as conversion_utils\n",
    "from collections import defaultdict\n",
    "import geopy.distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import src.definitions as definitions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from src.data_manager import student_life_var_binned_data_manager\n",
    "importlib.reload(student_life_var_binned_data_manager)\n",
    "importlib.reload(student_utils)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopy.distance as euclidean_distances\n",
    "COORD_DIST = lambda p1, p2: euclidean_distances.distance(p1, p2).km\n",
    "from scipy.spatial import ConvexHull\n",
    "from area import area\n",
    "from editdistance import eval as edit_distance\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "import scipy\n",
    "from datetime import datetime, timedelta\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'gps'\n",
    "def load_features(student_id=2):\n",
    "    path = \"{}/data/student_life_minimal_processed_data/student_{}\".format(module_path, student_id)\n",
    "    if (not os.path.exists(path)): return None\n",
    "    feats = {}\n",
    "    for _file in os.listdir(path):\n",
    "        if keyword not in _file and 'stress' not in _file: \n",
    "            continue\n",
    "        feat_path = path + \"/\" + _file\n",
    "        df = pd.read_csv(feat_path)\n",
    "        print('student {} loaded feat: {}'.format(student_id, _file))      \n",
    "        feat_name = _file.replace('.csv', '')\n",
    "        feats[feat_name] = df\n",
    "    return feats\n",
    "        \n",
    "    \n",
    "# feats = load_features(student_id=46)\n",
    "# print(len(feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location Features (8 total):\n",
    " - total distance covered in a day\n",
    " - maximum 2-point displacement in a day\n",
    " - distance standard deviatio\n",
    " - number of different areas visited by tiles approximation\n",
    " - total spatial coverage by convex hull,\n",
    " - difference in sequence of tiles covered compared to previous day\n",
    " - difference in sequence of clusters visited compared to previous day\n",
    " - distance entropy\n",
    "\n",
    "4 Temporal one-hot features \n",
    "- weekends, start of term, mid-term, end of term\n",
    "\n",
    "https://www.ucl.ac.uk/~ucfamus/papers/digitalbiomarkers17.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_time_to_df(df):\n",
    "    df.loc[:, 'time'] = pd.to_datetime(df.loc[:,'time'])\n",
    "    df = df.set_index('time')\n",
    "    return df\n",
    "location = feats['gps_details']\n",
    "location = index_time_to_df(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>stress</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-24 09:47:21</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2013-03-23 09:47:21, 2013-03-24 09:47:21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-24 10:45:09</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[2013-03-23 10:45:09, 2013-03-24 10:45:09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-24 10:45:11</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2013-03-23 10:45:11, 2013-03-24 10:45:11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     student_id  stress_level  stress  \\\n",
       "time                                                    \n",
       "2013-03-24 09:47:21          46             2     1.0   \n",
       "2013-03-24 10:45:09          46             4     2.0   \n",
       "2013-03-24 10:45:11          46             2     1.0   \n",
       "\n",
       "                                                          range  \n",
       "time                                                             \n",
       "2013-03-24 09:47:21  [2013-03-23 09:47:21, 2013-03-24 09:47:21]  \n",
       "2013-03-24 10:45:09  [2013-03-23 10:45:09, 2013-03-24 10:45:09]  \n",
       "2013-03-24 10:45:11  [2013-03-23 10:45:11, 2013-03-24 10:45:11]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-23 10:45:50 2013-03-24 10:45:50\n"
     ]
    }
   ],
   "source": [
    "def s_filter(pd, agg_fn, date_range):\n",
    "    lo, hi = date_range\n",
    "    tmp = pd.loc[lo:hi]\n",
    "    out = agg_fn(tmp)\n",
    "    if out is float('NaN'):\n",
    "        return 0.0\n",
    "    return out\n",
    "    \n",
    "def get_stress_labels_with_time(feats):\n",
    "    stress = feats['stress_details'].copy()\n",
    "    stress = stress.drop_duplicates(subset='time', keep='last')\n",
    "    N = len(stress)\n",
    "#     stress_median = stress['stress_level'].median()\n",
    "    stress_median = 2\n",
    "    stress = index_time_to_df(stress)\n",
    "    stress['stress'] = [0.0 for i in range(N)]\n",
    "    stress['range'] = [None for i in range(N)]\n",
    "    def bin_stress_to_classes(stress_val):\n",
    "        if stress_val < stress_median: \n",
    "            return 0\n",
    "        elif stress_val > stress_median:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "        return bin_stress_to_classes\n",
    "\n",
    "    for idx in stress.index:\n",
    "        raw_stress_val = stress.loc[idx]['stress_level']\n",
    "        if(raw_stress_val is float('nan')):\n",
    "            print(\"NAN\")\n",
    "            continue\n",
    "        stress.at[idx,'stress'] = bin_stress_to_classes(raw_stress_val)\n",
    "        stress.at[idx, 'range'] = [idx-pd.Timedelta(days=1), idx]\n",
    "    return stress\n",
    "stress_labels = get_stress_labels_with_time(feats)\n",
    "display(stress_labels[:3])\n",
    "a,b = stress_labels.iloc[4]['range']\n",
    "print(a,b)\n",
    "# display(stress_labels[a-pd.Timedelta(days=1):a+pd.Timedelta(days=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1, 2) Total Distance Covered, Max Displacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_distance(_location):\n",
    "    location = _location.copy()\n",
    "    location['distance'] = [0 for x in range(len(location))]\n",
    "\n",
    "    for i in range(1, len(location)):\n",
    "        row_cur = location.iloc[i]\n",
    "        row_prev = location.iloc[i-1]\n",
    "        p1 = (row_cur['latitude'], row_cur['longitude'])\n",
    "        p2 = (row_prev['latitude'], row_prev['longitude'])\n",
    "        dist = euclidean_distances.distance(p1, p2).km\n",
    "        location.iloc[i, location.columns.get_loc('distance')]= dist\n",
    "    return location\n",
    "\n",
    "def get_feat_distance_covered(distance, stress_labels):\n",
    "    # display(conversation)\n",
    "    out = stress_labels.copy()\n",
    "    N = len(out)\n",
    "    out['distance'] = [0.0 for i in range(N)]\n",
    "    out['displacement'] = [0.0 for i in range(N)]\n",
    "    \n",
    "    def _sum(subset):\n",
    "        return subset.sum()\n",
    "    def _max(subset):\n",
    "        return subset.max()\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        dist_feats = distance['distance']\n",
    "        out.at[idx, 'distance'] = s_filter(dist_feats, _sum, date_range)\n",
    "        out.at[idx, 'displacement'] = s_filter(dist_feats, _max, date_range)\n",
    "        out = out.fillna(0.0)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# distance = to_distance(location)\n",
    "# next_stress_labels = get_feat_distance_covered(distance, stress_labels)\n",
    "# display(next_stress_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_distance(distance, stress_labels):\n",
    "    out = stress_labels.copy()\n",
    "    N = len(out)\n",
    "    out['distance_std'] = [0.0 for i in range(N)]\n",
    "    \n",
    "    def _std(subset):\n",
    "        return subset.std()\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        dist_feats = distance['distance']\n",
    "        out.at[idx, 'distance_std'] = s_filter(dist_feats, _std, date_range)\n",
    "        out = out.fillna(0.0)\n",
    "    return out\n",
    "\n",
    "# next_stress_labels_2 = get_std_distance(distance, next_stress_labels)\n",
    "# display(next_stress_labels_2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Spatial Tile - unique tile visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_spatial_map(_location, bound=50):\n",
    "    location = _location.copy()\n",
    "    lats  = location['latitude']\n",
    "    longs = location['longitude'] \n",
    "    min_lat, max_lat = lats.min(), lats.max()\n",
    "    min_long, max_long = longs.min(), longs.max()\n",
    "    TL = [min_lat, max_long]\n",
    "    TR = [max_lat, max_long]\n",
    "    BL = [min_lat, min_long]\n",
    "    BR = [max_lat, min_long]\n",
    "\n",
    "    location['area'] = [\"\" for x in range(len(location))]\n",
    "    for i in range(len(location)):\n",
    "        row = location.iloc[i]\n",
    "        lat, long = row['latitude'], row['longitude']\n",
    "        x_dist = COORD_DIST([lat, long], [min_lat, long])\n",
    "        y_dist = COORD_DIST([lat, long], [lat, min_long])\n",
    "        hash_x, hash_y = int(x_dist/bound), int(y_dist/bound)\n",
    "        hash_xy = \"{}-{}\".format(hash_x, hash_y)\n",
    "        location.iloc[i, location.columns.get_loc('area')] = hash_xy\n",
    "    return pd.DataFrame(location['area'])\n",
    "\n",
    "def bin_areas_by_day(areas, stress_labels):\n",
    "    def bin_day(subset):\n",
    "        tiles = [x[0] for x in subset.values]\n",
    "        return tiles\n",
    "    \n",
    "    out = stress_labels.copy()\n",
    "    N = len(out)\n",
    "    out['area'] = [[] for i in range(N)]\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        out.at[idx, 'area'] = s_filter(areas, bin_day, date_range)\n",
    "    return out\n",
    "\n",
    "# areas = build_spatial_map(location) # time -> tile\n",
    "# # display(areas[:6].values)\n",
    "# next_stress_labels_3 = bin_areas_by_day(areas, next_stress_labels_2)\n",
    "# display(area_days[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_tile_feats(stress_labels):\n",
    "    out = stress_labels.copy()\n",
    "    N = len(stress_labels)\n",
    "    out['unique_tile_count'] = [0.0 for x in range(N)]\n",
    "    for i in range(N):\n",
    "        tile_set = set(out.iloc[i, out.columns.get_loc('area')])\n",
    "        out.iloc[i, out.columns.get_loc('unique_tile_count')] = len(tile_set)\n",
    "    return out\n",
    "        \n",
    "# next_stress_labels_4 = unique_tile_feats(next_stress_labels_3)\n",
    "# display(next_stress_labels_4[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull_feats(locations, stress_labels):\n",
    "    def bin_convex(subset):\n",
    "        coords = subset[['latitude','longitude']].values\n",
    "        if(len(coords)<=2):\n",
    "            return 0\n",
    "        hull = ConvexHull(coords)\n",
    "        points = [list(hull.points[ix]) for ix in hull.vertices]\n",
    "        obj = {'type':'Polygon','coordinates':[points]}\n",
    "        area_result = area(obj)/100\n",
    "        return area_result\n",
    "\n",
    "    N = len(stress_labels)\n",
    "    out = stress_labels.copy()\n",
    "    out['convex_hull_area'] = [[] for i in range(N)]\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        out.at[idx, 'convex_hull_area'] = s_filter(locations, bin_convex, date_range)\n",
    "    return out\n",
    "    \n",
    "\n",
    "# next_stress_labels_5 = convex_hull_feats(location, next_stress_labels_4)\n",
    "# display(next_stress_labels_5[:3])\n",
    "# display(next_stress_labels_5['convex_hull_area'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) difference in sequence of tiles covered compared to previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_edit_dist_feats(stress_labels):\n",
    "    N = len(stress_labels)\n",
    "    out = stress_labels.copy()\n",
    "    out['tile_change'] = [0.0 for i in range(N)]\n",
    "    for i in range(1, N):\n",
    "        cur_tiles  = out.iloc[i, out.columns.get_loc('area')]\n",
    "        prev_tiles = out.iloc[i-1, out.columns.get_loc('area')]\n",
    "        change = edit_distance(cur_tiles, prev_tiles)\n",
    "        out.iloc[i, out.columns.get_loc('tile_change')] = change\n",
    "    return out\n",
    "\n",
    "# next_stress_labels_6 = prev_edit_dist_feats(next_stress_labels_5)\n",
    "# display(next_stress_labels_6[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) difference in sequence of clusters visited compared to previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_cluster_feats(locations, stress_labels):\n",
    "    def bin_location_cluster(subset):\n",
    "        X = np.array(subset['cluster'].values.tolist())\n",
    "        if (len(X)<=0): \n",
    "            return 0\n",
    "        ms = MeanShift()\n",
    "        ms.fit(X)\n",
    "        c = len(ms.cluster_centers_)\n",
    "        return c\n",
    "    \n",
    "    tmp = locations.copy()\n",
    "    tmp['cluster'] = locations[['latitude','longitude']].values.tolist()\n",
    "    \n",
    "    N = len(stress_labels)\n",
    "    out = stress_labels.copy()\n",
    "    out['cluster'] = [0.0 for i in range(N)]\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        out.at[idx, 'cluster'] = s_filter(tmp, bin_location_cluster, date_range)\n",
    "    return out\n",
    "    \n",
    "# next_stress_labels_7 = location_cluster_feats(location, next_stress_labels_6)\n",
    "# display(next_stress_labels_7[:3])\n",
    "# display(next_stress_labels_7['cluster'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8) Shannon Entropy every 10 minutes per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_feats(distance, stress_labels):\n",
    "    def bin_shannon(subset):\n",
    "        x = subset['distance'].values\n",
    "        entropy = scipy.stats.entropy(x)\n",
    "        return entropy\n",
    "    \n",
    "    tmp = pd.DataFrame(distance['distance'].copy())\n",
    "    tmp = tmp.resample(\"10T\").sum()\n",
    "    tmp = tmp.fillna(0.0)\n",
    "    \n",
    "    N = len(stress_labels)\n",
    "    out = stress_labels.copy()\n",
    "    out['entropy'] = [0.0 for i in range(N)]\n",
    "    \n",
    "    for idx in out.index:\n",
    "        date_range = out.at[idx,'range']\n",
    "        out.at[idx, 'entropy'] = s_filter(tmp, bin_shannon, date_range)\n",
    "        \n",
    "    return out\n",
    "    \n",
    "# display(distance)\n",
    "# next_stress_levels_8 = entropy_feats(distance, next_stress_labels_7)\n",
    "# display(next_stress_levels_8[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (9-12) Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_YEAR = lambda x: x.astype('datetime64[Y]').astype(int) + 1970\n",
    "TO_MONTH = lambda x: x.astype('datetime64[M]').astype(int)  % 12 + 1\n",
    "TO_DAY = lambda x: x.astype('datetime64[D]').astype(int)\n",
    "def to_year_month_date(x):\n",
    "    year, month, day = str(x).split('T')[0].split(\"-\")\n",
    "    year, month, day = int(year), int(month), int(day)\n",
    "    return year, month, day\n",
    "\n",
    "def is_weekend(dt64):\n",
    "    y,m,d = to_year_month_date(dt64)\n",
    "    x = datetime(y,m,d,0,9)\n",
    "    return x.isoweekday() in [6,7]\n",
    "\n",
    "def temporal_feats(stress_levels):\n",
    "    N = len(stress_levels)\n",
    "    out = stress_levels.copy()\n",
    "    mid_start_raw = '2013-04-15T00:00:00.000000000'#Monday, April 15, 2013\n",
    "    mid_end_raw = '2013-05-06T00:00:00.000000000'# Monday, May 6, 2013\n",
    "    mid_start = np.datetime64(mid_start_raw)\n",
    "    mid_end   = np.datetime64(mid_end_raw)\n",
    "    out['start_term'] = [0.0 for i in range(N)]\n",
    "    out['end_term'] = [0.0 for i in range(N)]\n",
    "    out['mid_term'] = [0.0 for i in range(N)]\n",
    "    out['weekends'] = [0.0 for i in range(N)]\n",
    "    for idx in out.index.values:\n",
    "        weekend_col = out.columns.get_loc('weekends')\n",
    "        out.at[idx,'weekends'] = int(is_weekend(idx))\n",
    "        x_term_col = \"\"\n",
    "        if (idx <= mid_start):\n",
    "            x_term_col = 'start_term'\n",
    "        elif (idx >= mid_end):\n",
    "            x_term_col = 'end_term'\n",
    "        else:\n",
    "            x_term_col = 'mid_term'\n",
    "        out.at[idx, x_term_col] = 1\n",
    "    return out\n",
    "        \n",
    "        \n",
    "# next_stress_level_9 = temporal_feats(next_stress_levels_8)\n",
    "# display(next_stress_level_9[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def build_features(feats, stress_labels, student_id=2):\n",
    "    t0 = time.time()\n",
    "    location = feats['gps_details']\n",
    "    location = index_time_to_df(location)\n",
    "    # 1,2,3 - basic stats\n",
    "    distance = to_distance(location)\n",
    "    stress_labels = get_feat_distance_covered(distance, stress_labels)\n",
    "    stress_labels = get_std_distance(distance, stress_labels)\n",
    "    \n",
    "    # 4 - unique tiles\n",
    "    areas = build_spatial_map(location) # time -> tile\n",
    "    stress_labels = bin_areas_by_day(areas, stress_labels)\n",
    "    stress_labels = unique_tile_feats(stress_labels)\n",
    "    \n",
    "    # 5 - convex\n",
    "    stress_labels = convex_hull_feats(location, stress_labels)\n",
    "    \n",
    "    # 6 - edit-disatance tiles\n",
    "    stress_labels = prev_edit_dist_feats(stress_labels)\n",
    "\n",
    "    # 7 - cluster\n",
    "    stress_labels = location_cluster_feats(location, stress_labels)\n",
    "    \n",
    "    # 8 - entropy\n",
    "    stress_labels = entropy_feats(distance, stress_labels)\n",
    "    \n",
    "    # 9,10,11,12 - temporal\n",
    "    stress_labels = temporal_feats(stress_labels)\n",
    "    \n",
    "    feature_set = stress_labels\n",
    "    print('student {} features built: {} sec'.format(student_id, time.time()-t0))\n",
    "#     feature_set = pd.concat([total_distance, max_displacement, std_distances, unique_tiles, tile_changes, \n",
    "#                              convex_areas, location_cluster, entropies, temporal_data], axis=1, sort=False)\n",
    "    \n",
    "    features_list = ['distance', 'displacement', 'distance_std', 'unique_tile_count', 'convex_hull_area',\n",
    "                    'tile_change','cluster', 'entropy', 'start_term', 'end_term', 'mid_term', 'weekends', 'stress'] \n",
    "    feature_set = pd.DataFrame(feature_set[features_list])\n",
    "    feature_set = feature_set.loc[:,~feature_set.columns.duplicated()]\n",
    "    return feature_set\n",
    "    \n",
    "# build_features(feats, stress_labels, student_id=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels - stress\n",
    "def build_dataset(student_id=43):\n",
    "    feats = load_features(student_id=student_id)\n",
    "    if (feats is None or 'gps_details' not in feats or 'stress_details' not in feats): \n",
    "        return None\n",
    "    stress_labels = get_stress_labels_with_time(feats)\n",
    "    dataset = build_features(feats, stress_labels, student_id = student_id)\n",
    "#     dataset = pd.concat([features, stress_labels], axis=1, join='inner', sort=False)\n",
    "    dataset['student_id'] = [student_id for i in range(len(dataset))]\n",
    "    dataset = dataset.reset_index()\n",
    "    dataset = dataset.fillna(0.0)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student 1 loaded feat: stress_details.csv\n",
      "student 1 loaded feat: gps_details.csv\n",
      "student 1 features built: 10.538377046585083 sec\n",
      "student 1 data-length: 36\n",
      "student 2 loaded feat: stress_details.csv\n",
      "student 2 loaded feat: gps_details.csv\n",
      "student 2 features built: 10.951153755187988 sec\n",
      "student 2 data-length: 35\n",
      "student 3 loaded feat: stress_details.csv\n",
      "student 3 loaded feat: gps_details.csv\n",
      "student 3 features built: 20.277439832687378 sec\n",
      "student 3 data-length: 34\n",
      "student 4 loaded feat: stress_details.csv\n",
      "student 4 loaded feat: gps_details.csv\n",
      "student 4 features built: 9.469982147216797 sec\n",
      "student 4 data-length: 46\n",
      "student 5 loaded feat: stress_details.csv\n",
      "student 5 loaded feat: gps_details.csv\n",
      "student 5 features built: 0.9095640182495117 sec\n",
      "student 5 data-length: 13\n",
      "student 7 loaded feat: stress_details.csv\n",
      "student 7 loaded feat: gps_details.csv\n",
      "student 7 features built: 5.281459808349609 sec\n",
      "student 7 data-length: 58\n",
      "student 8 loaded feat: stress_details.csv\n",
      "student 8 loaded feat: gps_details.csv\n",
      "student 8 features built: 28.259878873825073 sec\n",
      "student 8 data-length: 90\n",
      "student 9 loaded feat: stress_details.csv\n",
      "student 9 loaded feat: gps_details.csv\n",
      "student 9 features built: 0.7876608371734619 sec\n",
      "student 9 data-length: 8\n",
      "student 10 loaded feat: stress_details.csv\n",
      "student 10 loaded feat: gps_details.csv\n",
      "student 10 features built: 20.793843030929565 sec\n",
      "student 10 data-length: 112\n",
      "student 12 loaded feat: stress_details.csv\n",
      "student 12 loaded feat: gps_details.csv\n",
      "student 12 features built: 22.060564041137695 sec\n",
      "student 12 data-length: 35\n",
      "student 13 loaded feat: stress_details.csv\n",
      "student 14 loaded feat: stress_details.csv\n",
      "student 14 loaded feat: gps_details.csv\n",
      "student 14 features built: 12.9153311252594 sec\n",
      "student 14 data-length: 41\n",
      "student 15 loaded feat: stress_details.csv\n",
      "student 15 loaded feat: gps_details.csv\n",
      "student 15 features built: 3.3250198364257812 sec\n",
      "student 15 data-length: 16\n",
      "student 16 loaded feat: stress_details.csv\n",
      "student 16 loaded feat: gps_details.csv\n",
      "student 16 features built: 29.611164808273315 sec\n",
      "student 16 data-length: 112\n",
      "student 17 loaded feat: stress_details.csv\n",
      "student 17 loaded feat: gps_details.csv\n",
      "student 17 features built: 27.97571873664856 sec\n",
      "student 17 data-length: 47\n",
      "student 18 loaded feat: stress_details.csv\n",
      "student 18 loaded feat: gps_details.csv\n",
      "student 18 features built: 8.702844858169556 sec\n",
      "student 18 data-length: 20\n",
      "student 19 loaded feat: stress_details.csv\n",
      "student 19 loaded feat: gps_details.csv\n",
      "student 19 features built: 29.00635004043579 sec\n",
      "student 19 data-length: 96\n",
      "student 20 loaded feat: stress_details.csv\n",
      "student 20 loaded feat: gps_details.csv\n",
      "student 20 features built: 3.640994071960449 sec\n",
      "student 20 data-length: 14\n",
      "student 22 loaded feat: stress_details.csv\n",
      "student 22 loaded feat: gps_details.csv\n",
      "student 22 features built: 18.907567024230957 sec\n",
      "student 22 data-length: 60\n",
      "student 23 loaded feat: stress_details.csv\n",
      "student 23 loaded feat: gps_details.csv\n",
      "student 23 features built: 11.43199896812439 sec\n",
      "student 23 data-length: 47\n",
      "student 24 loaded feat: stress_details.csv\n",
      "student 24 loaded feat: gps_details.csv\n",
      "student 24 features built: 10.363415241241455 sec\n",
      "student 24 data-length: 48\n",
      "student 25 loaded feat: stress_details.csv\n",
      "student 25 loaded feat: gps_details.csv\n",
      "student 25 features built: 3.9960970878601074 sec\n",
      "student 25 data-length: 25\n",
      "student 27 loaded feat: stress_details.csv\n",
      "student 27 loaded feat: gps_details.csv\n",
      "student 27 features built: 11.09913182258606 sec\n",
      "student 27 data-length: 30\n",
      "student 30 loaded feat: stress_details.csv\n",
      "student 30 loaded feat: gps_details.csv\n",
      "student 30 features built: 9.350160837173462 sec\n",
      "student 30 data-length: 35\n",
      "student 31 loaded feat: stress_details.csv\n",
      "student 31 loaded feat: gps_details.csv\n",
      "student 31 features built: 6.617948293685913 sec\n",
      "student 31 data-length: 17\n",
      "student 32 loaded feat: stress_details.csv\n",
      "student 32 loaded feat: gps_details.csv\n",
      "student 32 features built: 22.30189800262451 sec\n",
      "student 32 data-length: 72\n",
      "student 33 loaded feat: stress_details.csv\n",
      "student 33 loaded feat: gps_details.csv\n",
      "student 33 features built: 13.530806064605713 sec\n",
      "student 33 data-length: 63\n",
      "student 34 loaded feat: stress_details.csv\n",
      "student 34 loaded feat: gps_details.csv\n",
      "student 34 features built: 4.660394906997681 sec\n",
      "student 34 data-length: 11\n",
      "student 35 loaded feat: stress_details.csv\n",
      "student 35 loaded feat: gps_details.csv\n",
      "student 35 features built: 16.354176998138428 sec\n",
      "student 35 data-length: 44\n",
      "student 36 loaded feat: stress_details.csv\n",
      "student 36 loaded feat: gps_details.csv\n",
      "student 36 features built: 20.99623703956604 sec\n",
      "student 36 data-length: 62\n",
      "student 39 loaded feat: stress_details.csv\n",
      "student 39 loaded feat: gps_details.csv\n",
      "student 39 features built: 4.165151119232178 sec\n",
      "student 39 data-length: 15\n",
      "student 41 loaded feat: stress_details.csv\n",
      "student 41 loaded feat: gps_details.csv\n",
      "student 41 features built: 6.577538013458252 sec\n",
      "student 41 data-length: 15\n",
      "student 42 loaded feat: stress_details.csv\n",
      "student 42 loaded feat: gps_details.csv\n",
      "student 42 features built: 10.941386938095093 sec\n",
      "student 42 data-length: 38\n",
      "student 43 loaded feat: stress_details.csv\n",
      "student 43 loaded feat: gps_details.csv\n",
      "student 43 features built: 16.39510703086853 sec\n",
      "student 43 data-length: 82\n",
      "student 44 loaded feat: stress_details.csv\n",
      "student 44 loaded feat: gps_details.csv\n",
      "student 44 features built: 19.50058913230896 sec\n",
      "student 44 data-length: 92\n",
      "student 45 loaded feat: stress_details.csv\n",
      "student 45 loaded feat: gps_details.csv\n",
      "student 45 features built: 7.188355922698975 sec\n",
      "student 45 data-length: 32\n",
      "student 46 loaded feat: stress_details.csv\n",
      "student 46 loaded feat: gps_details.csv\n",
      "student 46 features built: 12.018701076507568 sec\n",
      "student 46 data-length: 38\n",
      "student 47 loaded feat: stress_details.csv\n",
      "student 47 loaded feat: gps_details.csv\n",
      "student 47 features built: 9.639475107192993 sec\n",
      "student 47 data-length: 18\n",
      "student 49 loaded feat: stress_details.csv\n",
      "student 49 loaded feat: gps_details.csv\n",
      "student 49 features built: 19.087990760803223 sec\n",
      "student 49 data-length: 66\n"
     ]
    }
   ],
   "source": [
    "STUDENTS_LIST = [1]\n",
    "STUDENTS_LIST = [1, 57, 24]\n",
    "STUDENTS_LIST = [24, 57, 42, 7, 2]\n",
    "STUDENTS_LIST = [24, 57, 42, 7, 2, 46, 33]\n",
    "STUDENTS_LIST = [24, 57, 42, 7, 2, 46, 33, 49, 4]\n",
    "STUDENTS_LIST = [1, 2,4, 7,10, 22, 24, 33, 42, 46, 49, 53, 57]\n",
    "STUDENTS_LIST = list(range(1, 50))\n",
    "datasets = []\n",
    "for sid in STUDENTS_LIST:\n",
    "    dataset = build_dataset(student_id=sid)\n",
    "    if (dataset is None): \n",
    "        continue\n",
    "    print(\"student {} data-length: {}\".format(sid, len(dataset)))\n",
    "    datasets.append(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1723"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset = pd.concat(datasets, axis=0, sort=False)\n",
    "all_dataset = all_dataset.sample(frac=1)\n",
    "display(len(all_dataset))\n",
    "# display(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nsimsiri/Documents/code/ml/MultiRes/student_life/data/gatis-new-49.pkl\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_path = module_path + \"/data\"\n",
    "file_path = data_path + \"/gatis-new-{}.pkl\".format(len(STUDENTS_LIST))\n",
    "print(file_path)\n",
    "print(os.path.exists(data_path))\n",
    "all_dataset.to_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = pd.read_pickle(file_path)\n",
    "display(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss = None\n",
    "ss = pd.DataFrame(all_dataset['stress']).copy()\n",
    "print(type(ss))\n",
    "ss['count'] = [1.0 for i in range(len(ss))]\n",
    "ss = pd.DataFrame(ss)\n",
    "display(ss[:3])\n",
    "rss = ss.groupby('stress').sum()\n",
    "print(rss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
